********************train.py****************************
10-11:设置数据地址
	15:设置类别数n_classes(加背景)
	16:设置使用GPU/CPU
19-20:是指是否继续上一次训练
	21:批次设置
	22:迭代次数
	23:线程数
	24:隔几个批次打印一次log
26-27  :学习率策略
	28:动量设置
	29:weight decay设置
	30:未知
	32:cudnn.benchmark = True   总的来说，大部分情况下，设置这个 flag 可以让内置的 cuDNN 的 auto-tuner 自动寻找最适合当前配置的高效算法，来达到优化运行效率的问题。
        40:进入main函数：(更改后)
		42:声明全局变量
		44:是否接着上次继续训练－－－－否
			45:设置变量start_epoch = 0
			46:***实例化一个ssd对象***－－－－转移程序到ssd类的定义处model.py→323（class SSD300(nn.Module):）
				335:定义类别
				337:定义VGG部分
					20-46:VGG定义部分(self.base = VGGBase())
					51	 :load_pretrained_layers→89
							OrderedDict-----记住顺序的dict－－－－－－掌握字典的一般调用
							102-103:提取出自己所建立网络的各个卷积名称，此时网络已经建立，权重为随机初始化
							106-107:从 torchvision.models.vgg16加载与训练权重
							110-111:加载VGG16中的除FC6,FC7全连接的所有卷积权重
							115-123:加载fc6,fc7权重（通过decimate变形）
							129	     :通过nn.model中的load_state_dict加载参数
							131	     :打印加载完毕
				338:定义增加的辅助卷积池化层(self.aux_convs = AuxiliaryConvolutions())
					143-153:增加conv8-11
					15５	:初始化权重→def init_conv2d(self):
							162-165:权重采用xavier方式初始化nn.init.xavier_uniform_（保证输入与输出方差相同，防止梯度消失问题），偏置采用常数初始化nn.init.constant_
				339:定义预测卷积层→class PredictionConvolutions(nn.Module):
					210	:定义类别
					213-218:每个特征层生成默认框的个数（4,6,6,6,4,4）
					222-227:位置预测卷积定义
					230-235:类别预测卷积定义
					238	:初始化网络参数
							244-247:权重采用xavier方式初始化nn.init.xavier_uniform_（保证输入与输出方差相同，防止梯度消失问题），偏置采用常数初始化nn.init.constant_
				343－344:对conv4_3进行l2正则化并设置重缩放（－－－不明白－－－）
				347:创建初始框（8732个）self.priors_cxcy = self.create_prior_boxes()
					381-386:设置特征图大小
					388-393:设置目标尺度
					395-400:设置长宽比
					402:获取feature map的名称
					404:设置初始框数组
					406-423:获得所有初始框
					425:将初始框从list变为FloatTensor并放入GPU
					426:将所有的框限制在0-1之间（用clamp_,带_说明结果返回给自身）
			16-55:针对不同权重设置不同学习率（对需要进行求导并为偏置的设置２背学习率，其他的用原始学习率）
		58:是否接着上次继续训练－－－－是
			59:加载上一次的保存的训练模型
			60:设置开始epoch
			61:打印开始epoch
			62:加载上次的模型
			63:加载上次的优化器
		65:将model放入GPU训练
		66:多框损失类－－－需要接收一个参数priors_cxcy－－即初始框
			model.py→class MultiBoxLoss(nn.Module):
			548:init----初始框，threshold，neg_pos_ratio，alpha？
			550:接受初始框(8732*4)
			551:cxcy_to_xy(将初始框从中心尺寸坐标转换为边界尺寸坐标)
			552:设置threshold
			553:设置neg_pos_ratio
			554:设置alpha
			556:设置smooth_l1
			557:设置cross_entropy
			559-656:前向传播计算正负样本。。。未仔细看，需要仔细研究
		69:制作样本迭代器(PascalVOCDataset)继承了torch.utils.data中的Dataset父类，重写了__init__,__getitem__,__len__,collate_fn函数实现了一个自制的迭代器
			69:进入PascalVOCDataset子函数(datasets.py)
				20:将train或test转换为全大写
				22:判断
				24:加载数据地址
				25:设置keep_difficult
				28-32:读取训练集数据（位置和标记）
				33:判断标记的长度是否等于图片的长度
				37:迭代器设置（其中做了数据增强）
		72:封装到DataLoader，设置批次
		79-81:设置学习率衰减策略
		83:开始迭代训练
			87-88:判断是否需要减小学习率
			92-96:训练一次样本→进入train函数
				113:设置状态，训练or测试
				115-117:设置批次时间记录节点
				118:记录log
				119:计时开始
				124-125:循环遍历所有批次样本（所有样本均为标准化后的图像）
				128:展示所有训练图片
				131-133:将图像，标签，真值框放入GPU
				136:前向传播获得预测框和类别分数
					进入类SSD300的forward方法进行前向计算
					357:vgg运算获得两张特征图conv4和conv7
						62-77:卷积，池化，激活函数运算
						78:保存conv4卷积后的特征图[10, 512, 38, 38]
						79-88:卷积，池化，激活函数运算
						88:保存conv7卷积后的特征图
						89:返回保存的conv4和conv7
					360-361:L2正则化
					362:Rescale----未明白
					366:附加网络获得剩余的４个特征图(进入AuxiliaryConvolutions)
						174-175:conv8计算过程
						176:保存conv8卷积后的特征图
						178-179:conv9计算过程
						180:保存conv9卷积后的特征图
						182-183:conv10计算过程
						184:保存conv10卷积后的特征图
						186:conv11计算过程
						187:保存conv11卷积后的特征图
						190:返回conv8-ocnv11的特征图
					370:预测类别和框的位置PredictionConvolutions
						261:获取每个批次图像的数量
						263:获得预测框的特征图
						264:运用permute修改维度组合和contiguous为后面的view做准备
						267:获得在conv4特横图上最终的预测框，变形为（批次大小，5776，4）
						269-271:同理获得conv7的预测框
						273-275:同理获得conv8的预测框
						277-279:同理获得conv9的预测框
						281-283:同理获得conv10的预测框
						285-287:同理获得conv11的预测框
						289-315:同获得预测框一样获得类别得分
						319-320:拼接所有的预测框和类别得分
						323:返回预测框和类别得分
					372:返回预测框和类别得分
				139:计算loss＊＊＊＊＊＊MultiBoxLoss＊＊＊＊＊＊＊＊＊＊
					forward()
					574:获得批次信息
					575:获得真值框的个数
					576:获得类别数
					577:判断初始框＝预测框＝预测类别分数
					578-579:设置存放真框和真类别的空间
					581-585:存放绘制真值框，初始框，预测框的位置
					588:循环遍历每一张图片
						589:获得这张图片真值框的数量
						590:真值框与初始框的IOU
							373:每个真值框与8732个初始框相交大小
							376-377:计算真值框和初始框的面积
							381:不懂
							383:返回结果
						594:通过n行（n个真值框）之间的纵向对比，找出每个初始框与较大的真值的iou
						602:通过在每行的8732个元素之间取最大值，找出每个真值框对应iou最大的初始框
						605:显示初始框，真值框，预测框
						609:修改object_for_each_prior里面真值框对应的最大IOU初始框的索引值，后面到labels[i]中找到对应的标签
						611:将真值框匹配的初始框分数置１，因为这个框与真值框的IOU最大，所以作者直接设置为１
						615:给每一个初始框打标签，labels[i]是这个图像拥有的真值框的标签，object_for_each_prior为所有初始框的信息（大部分是通过最大IOU确定的归属类别，小部分n（真值框的个数）在上一步人为设置了一下）
						617:对上面的初始框标签进行修正，IOU小于阈值的直接设置为０背景，因为真值框所对应的初始框之前已经设置为１，所以不会变化
						620:存放这张图片的初始框标签，整个批次处理完后统一计算loss
						623:计算真值框和初始框的偏移值作为预测框的拟合对象（即编码过程）
							utils.py→cxcy_to_gcxgcy
							326:encode---groundtruth 和anchor坐标的偏移量
						626:将初始框中标签不为０（非背景）的True给positive_priors
						630:用smooth_l1计算位置损失？？？predicted_locs[positive_priors]选出正样本
						643:计算每个图像里面有多少个正样本
						644:根据正样本的个数计算负样本(难分负样本)的个数:正负样本比为 self.neg_pos_ratio
						647:计算所有prior的损失
						648:变形成为批次+n_prior的形式
						651:将正样本的损失取出来
						655:复制所有的分类损失
						656:将正样本的损失都设置为０,剩下的则全为负样本
						657:对负样本进行降序排列
						658:unsqueeze(0)在第０维增加一个维度，expand_as()这个函数就是把一个tensor变成和函数括号内一样形状的tensor
						659:制作难分负样本序列
						660:根据难分负样本序列筛选难分负样本
						663:计算平均confidence损失（正样本损失加负样本损失）
				142-143:优化器梯度清零，loss反向传播
				146-147:未用到
				150:更新模型参数
				152-154:计时结束
				157-165:打印训练状态
				166:所有样本训练完一遍后关闭log文件
				167:删除变量（del）
********************train.py****************************

-----------------------------加入可视化特征图并保存－－－－－－－－－－－－－－－－－－－－－
utils.py→show_feature_map

-----------------------------加入可视化真值框、初始框、预测框并保存－－－－－－－－－－－－－－－－－－－－－
utils.py→show_groundtruth_priorbox_predictbox

-----------------------------加入可视化训练的图片并保存－－－－－－－－－－－－－－－－－－－－－
utils.py→show_train_pic

-----------------------------加入可视化样本和增强后的样本并保存－－－－－－－－－－－－－－－－－－－－－
utils.py→show_transform_pic
